{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PDF Summarizer Project\n",
        "\n",
        "This project is designed to efficiently extract key information from research papers in PDF format, utilizing advanced AI models. It provides a structured pipeline for loading, chunking, and summarizing large PDF files, optimized for researchers and professionals.\n",
        "\n",
        "This project includes a **Streamlit** app that allows users to utilize the PDF summarization functionality through an intuitive interface.\n",
        "\n",
        "\n",
        "## Features\n",
        "\n",
        "### PDF Loading\n",
        "- Uses **PyPDFLoader** to extract content from PDF files.\n",
        "- Supports splitting large documents into manageable pages.\n",
        "\n",
        "### Chunk-Based Summarization\n",
        "- Dynamically splits raw text into smaller chunks with adjustable size and overlap for processing.\n",
        "- Recursive Splitting:\n",
        "\n",
        "  The splitter attempts to divide text at meaningful boundaries (e.g., paragraphs, sentences, words) to create chunks that make sense on their own, rather than cutting arbitrarily at the character limit.\n",
        "- Supports both **\"Stuff\"** and **\"Map-Reduce\"** chain methods for summarization.\n",
        "\n",
        "### Customizable Prompt Templates\n",
        "- **Stuff Chain Template**: Summarizes entire chunks directly, suitable for small documents.\n",
        "- **Map-Reduce Chain Template**: Breaks the process into mapping and reducing stages for better scalability and synthesis of complex documents.\n",
        "\n",
        "### Integration with GPT-3.5 Turbo\n",
        "- Utilizes **gpt-3.5-turbo-16k** for accurate and concise summaries.\n",
        "- Allows temperature and prompt-based customization for tailored outputs.\n",
        "\n",
        "---\n",
        "\n",
        "## Workflow\n",
        "\n",
        "### 1. Define and Load PDF\n",
        "- Input the PDF URL or file path.\n",
        "- Load and split content into chunks.\n",
        "\n",
        "### 2. Summarization Method\n",
        "- Use **\"stuff\"** for direct processing.\n",
        "- Use **\"map-reduce\"** for larger documents with more comprehensive synthesis.\n",
        "\n",
        "### 3. Prompt Integration\n",
        "- Leverages `map_prompt` and `combine_prompt` templates for tailored AI guidance.\n",
        "- Outputs summaries in bullet-point or final cohesive formats.\n",
        "\n",
        "### 4. Execution\n",
        "- Easily switch between methods by adjusting the function call parameters (`chunk_size`, `chunk_overlap`, and chain type).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cEuE_lbsSX8t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YIs4bngsPm8"
      },
      "source": [
        "## <font color=blue> TASK 1: Install and setup LangChain\n",
        "Welcome to this project notebook, which will serve as your guide to constructing your inaugural Generative AI application. Within this notebook, you'll encounter concise descriptions of each task to enhance your comprehension of the sequence. Our initial task commences with the importation of essential libraries required for this project.\n",
        "\n",
        "***Note: Before importing the libraries please ensure that all the library modules such as Langchain, Streamlit, PyPdf and other required libraries are installed on this notebook by running the pip command as shown below.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Wnvxw5okxYjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2f3592c-7495-4fec-bc7e-6639f40f29ee",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.22)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.2.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.3.22)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.57.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain_openai) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain_openai) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.40.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.0.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.10)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.22)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.10->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.10->langchain-community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.10->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.10->langchain-community) (2.27.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "#For installing the Langchain module associated with OpenAI LLM model\n",
        "!pip install langchain\n",
        "!pip install langchain_openai\n",
        "#For installing the Python library responsible for PDF upload\n",
        "!pip install pypdf\n",
        "#For installing the library responsible for web app development\n",
        "!pip install streamlit\n",
        "#For installing tokeniser library that asists with converting text strings into tokens recognizable by OpenAI models\n",
        "!pip install tiktoken\n",
        "#For installing the library used for invoking the environment file containing secret API key\n",
        "!pip install python-dotenv\n",
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "bJ0AR0gorTlF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dotenv\n",
        "from langchain_openai import OpenAI\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import streamlit as st"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=blue> Load OpenAI API Key to access LLM model\n",
        "\n",
        "## <font color=black>\n",
        "1. Go to https://platform.openai.com/api-keys\n",
        "2. Click on the '+ Creat new secret key button'\n",
        "3. Enter an identifier name(optional) and click on the \"Create secret key\" button\n",
        "4. Copy the API key to be used in the API.env file that you need to upload to Google Colab environment"
      ],
      "metadata": {
        "id": "bvtUejaS8v8T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "qtlBVZonvkf8"
      },
      "outputs": [],
      "source": [
        "# Load the .env file and invoke the secret API key from the file\n",
        "dotenv.load_dotenv('API.env')\n",
        "OpenAI.api_key = os.getenv(\"OPENAI_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRjptllP7Xgb"
      },
      "source": [
        "# <font color=blue> Load PDF file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "FL4FtXMkvocT"
      },
      "outputs": [],
      "source": [
        "pdf_url = \"https://www.medrxiv.org/content/10.1101/2021.07.15.21260605v1.full.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(pdf_url)\n",
        "pages = loader.load_and_split()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#number of pages\n",
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axDR3jjP8clC",
        "outputId": "757c6107-5876-4feb-ba20-a2aa5fd42bdd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "HEGnGRAe_op2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab9eb40-dc75-4426-d0af-96dd2d378512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COVID-19 Chest X-Ray Image Classification Using Deep Learning\n",
            "Gunther Correia Bacellar,1 Mallikarjuna Chandrappa,1 Rajlakshman Kulkarni,1 Soumava Dey1* \n",
            "Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, 61801, USA  \n",
            "*Correspondence: soumava2@illinois.edu; soumavadey87@gmail.com \n",
            "               \n",
            "ABSTRACT \n",
            "The rise of the coronavirus disease 2019 (COVID-19) pandemic has made it necessary to improve existing medical screening \n",
            "and clinical management of this disease. While COVID-19 patients are known to exhibit a variety of symptoms, the major \n",
            "symptoms include  fever, cough, and fatigue. Since these symptoms also appear in pneumonia patients, this creates \n",
            "complications in COVID-19 detection especially during the flu season. Early studies identified abnormalities in chest X -ray \n",
            "images of COVID -19 infected patient s that could be beneficial for disease diagnosis. Therefore, chest X -ray image -based \n",
            "disease classification has emerged as an alternative to aid medical diagnosis. However, manual detection of COVID-19 from a \n",
            "set of chest X-ray images comprising both COVID -19 and pneumonia cases is cumbersome and prone to huma n error. Thus, \n",
            "artificial intelligence techniques powered by deep learning algorithms,  which learn from radiography images and predict \n",
            "presence of COVID-19 have potential to enhance current diagnosis process. Towards this purpose, here we implemented a set \n",
            "of deep learning pre -trained models such as ResNet, VGG, Inception and EfficientNet in conjunction with developing a \n",
            "computer vision AI system based on our own convolutional neural network (CNN) model: Deep Learning in Healthcare (DLH)-\n",
            "COVID. All these CNN models cater to image classification exercise.  We used publicly available resources of 6,432 images \n",
            "and further strengthened our model by tuning hyperparameters to provide better generalization dur ing the model validation \n",
            "phase. Our final DLH-COVID model yielded the highest accuracy of 96% in detection of COVID-19 from chest X-ray images \n",
            "when compared to images of both pneumonia-affected and healthy individuals. Given the practicality of acquiring chest X-ray \n",
            "images by patients, we also developed a web application (link: https://toad.li/xray) based on our model to directly enable users \n",
            "to upload chest X-ray images and detect the presence of COVID -19 within a few seconds. Taken together, here we introduce \n",
            "a state-of-the-art artificial intelligence-based system for efficient COVID-19 detection and a user-friendly application that has \n",
            "the capacity to become a rapid COVID-19 diagnosis method in the near future.\n",
            " \n",
            "Keywords: COVID-19, Coronavirus detection, Deep learning, X-ray, Pneumonia, Classification \n",
            " \n",
            "1. INTRODUCTION    \n",
            "The COVID-19 is a viral infection that causes severe \n",
            "respiratory illness ranging from common cold to life \n",
            "threating diseases like Severe Acute Respiratory Syndrome \n",
            "(SARS) and Middle East Respiratory Syndrome (MERS). \n",
            "According to reports from the World Health Organization \n",
            "(WHO), major symptoms of COVID -19 are s imilar to that \n",
            "of common flu: fever, tiredness, dry cough, shortness of \n",
            "breath, aches and sore throat [1,2]. The similarities between \n",
            "COVID-19 and flu symptoms causes difficulties in detection \n",
            "of the coro navirus at early stages. It was found in some \n",
            "patients that the coronavirus, like other viruses and bacteria, \n",
            "also causes pneumonia, and the treatment for coronavirus \n",
            "induced pneumonia is different from other types of \n",
            "pneumonia. Moreover, bacterial pneumon ia infected \n",
            "patients require antibiotic treatment whereas viral \n",
            "pneumonia cases can be treated by intensive care [3]. \n",
            "Therefore, accurate and timely diagnosis of COVID -19 \n",
            "induced pneumonia is very important to save human lives as \n",
            "well as curbing the pandemic outbreak across the world. \n",
            "The WHO approved method of testing COVID -19 is \n",
            "the reverse transcription polymerase chain reaction (RT -\n",
            "PCR) where short sequences of RNA are analyzed to detect\n"
          ]
        }
      ],
      "source": [
        "#view page content\n",
        "print(pages[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyDp0eJj_hNd"
      },
      "source": [
        "## <font color=blue> TASK 2: Define the summarize pdf function\n",
        "Define the main function that will take pdf file path as an input and generate a summary of the file.\n",
        "\n",
        "### Recursive Splitting Logic\n",
        "\n",
        "- The method first tries to split the text into larger logical sections (e.g., paragraphs).\n",
        "- If the resulting sections are still too large (i.e., exceed `chunk_size`), it further breaks them into smaller parts (e.g., sentences).\n",
        "- This process continues recursively down to the smallest meaningful unit (e.g., words) until the chunks meet the desired size constraint.\n",
        "\n",
        "\n",
        "### Adding Overlap\n",
        "\n",
        "- After splitting the text into chunks, the method adds overlap between consecutive chunks based on the `chunk_overlap` parameter.\n",
        "- For example:\n",
        "  - If `chunk_size` is 1000 and `chunk_overlap` is 200:\n",
        "    - The first chunk might include characters 0-1000.\n",
        "    - The second chunk would include characters 800-1800.\n",
        "- This overlap ensures that critical context isn't lost between chunks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "kON5tJmk09Mp"
      },
      "outputs": [],
      "source": [
        "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap):\n",
        "    # Instantiate LLM model (GPT-3.5 Turbo)\n",
        "    llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
        "\n",
        "    # Load PDF file\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs_raw = loader.load()\n",
        "\n",
        "    # Create multiple documents\n",
        "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
        "\n",
        "    # Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
        "\n",
        "    # Summarize the chunks\n",
        "    chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
        "    summary = chain.invoke(docs_chunks, return_only_outputs=True)\n",
        "\n",
        "    # Return the summary\n",
        "    return summary['output_text']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8jP624HFsZyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "zZsZ5TGMM-WS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39929344-f004-4108-8f31-37385edef944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This study developed a deep learning model called DLH_COVID to classify COVID-19, pneumonia, and normal/healthy cases from chest X-ray images. The model was compared to pre-trained models and achieved the highest accuracy of 96% in detecting COVID-19. A web application was also developed based on the DLH_COVID model for users to upload chest X-ray images and detect the presence of COVID-19. The study highlights the potential of AI-based systems for efficient COVID-19 detection and diagnosis.\n"
          ]
        }
      ],
      "source": [
        "#Chunk size and chunk overlap values set to random value\n",
        "# Print summary by using chain type \"stuff\" or \"map_reduce\"\n",
        "print(summarize_pdf(pdf_url, 1000, 20))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_map_reduce_pdf(pdf_file_path, chunk_size, chunk_overlap):\n",
        "    # Instantiate LLM model (GPT-3.5 Turbo)\n",
        "    llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
        "\n",
        "    # Load PDF file\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs_raw = loader.load()\n",
        "\n",
        "    # Create multiple documents\n",
        "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
        "\n",
        "    # Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
        "\n",
        "    # Summarize the chunks\n",
        "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "    summary = chain.invoke(docs_chunks, return_only_outputs=True)\n",
        "\n",
        "    # Return the summary\n",
        "    return summary['output_text']"
      ],
      "metadata": {
        "id": "voLxqq-I7yD0"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summarize_map_reduce_pdf(pdf_url, 1000, 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSlPfooU8JWJ",
        "outputId": "db5100d9-3f2c-4d9d-fc0a-0e801454ff95"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This study developed a deep learning model called DLH-COVID to classify chest X-ray images for COVID-19 detection. The model achieved a 96% accuracy rate and a user-friendly web application was created for quick diagnosis. The study highlights the challenges in differentiating COVID-19 from pneumonia and the limitations of current testing methods. The DLH-COVID model shows promise as a rapid and efficient method for COVID-19 diagnosis, but further assessments are needed. The study used transfer learning and hyperparameter optimization techniques, and references various research papers on CNN models, medical imaging diagnosis, and AI for COVID-19 detection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvnt8H-L3Yzb"
      },
      "source": [
        "## <font color=blue> TASK 3: Add Prompt template to the summarizer function\n",
        "Leveraging prompt templates to extract key information from the reserach paper in more guided manner.\n",
        "\n",
        "### Stuff Method\n",
        "- Only uses `map_prompt`.\n",
        "- Suitable for smaller documents where all content can be processed in a single step.\n",
        "\n",
        "#### Map-Reduce Method\n",
        "A multi-stage processing approach divided into two key steps:\n",
        "\n",
        "##### 1. Map Stage\n",
        "- The input document is divided into smaller chunks.\n",
        "- Each chunk is processed individually to generate a separate summary.\n",
        "- This stage utilizes `map_prompt` to guide the summarization of each chunk.\n",
        "\n",
        "##### 2. Reduce Stage\n",
        "- Summaries from the map stage are combined into a comprehensive final summary.\n",
        "- This stage leverages `combine_prompt` to aggregate and synthesize the smaller summaries into one cohesive result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s2a87sV4Hkl"
      },
      "source": [
        "## <font color=blue> Define Prompt Templates"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=black> Prompt Template for Stuffing chain type"
      ],
      "metadata": {
        "id": "4Wy1_iJlfQRR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Zac7tS6p3YKU"
      },
      "outputs": [],
      "source": [
        "map_prompt_template = \"\"\"\n",
        "                       Write a summary of the research paper for an\n",
        "                       artficial intelligence researcher that includes\n",
        "                       main points and any important details in bullet points.{text}\n",
        "                      \"\"\"\n",
        "\n",
        "map_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=map_prompt_template,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=black> Add Combo Template for Map_Reduce chain type"
      ],
      "metadata": {
        "id": "Il7HTR6pfjsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combine_prompt_template = \"\"\"\n",
        "You will be given main points and any important details of a research paper in bullet points.\n",
        "Your goal is to give a final summary of the main research topic and findings\n",
        "which will be useful to an artificial intelligence researcher\n",
        "to grasp what was done during the research work.\n",
        "\n",
        "```{text}```\n",
        "\n",
        "FINAL SUMMARY:\n",
        "\"\"\"\n",
        "\n",
        "combine_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=combine_prompt_template,\n",
        ")"
      ],
      "metadata": {
        "id": "AaZoSIMDfMPu"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "6xyYdjJZEJJs"
      },
      "outputs": [],
      "source": [
        "# Modify the custom function to add the prompt templates\n",
        "def summarize_stuff_pdf(pdf_file_path, chunk_size, chunk_overlap, map_prompt):\n",
        "    # Instantiate LLM model\n",
        "    llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
        "\n",
        "    # Load PDF file\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs_raw = loader.load()\n",
        "\n",
        "    # Create multiple documents\n",
        "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
        "\n",
        "    # Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
        "\n",
        "    # Summarize the chunks\n",
        "    chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=map_prompt)\n",
        "\n",
        "    # Return the summary\n",
        "    summary = chain.invoke(docs_chunks, return_only_outputs=True)\n",
        "    return summary['output_text']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print summary using the map_prompt and combine prompt\n",
        "#Increasing the chunk size value might reduce the overall summarization time with map_reduce method\n",
        "print(summarize_stuff_pdf(pdf_url, 2000, 100, map_prompt))"
      ],
      "metadata": {
        "id": "_2bNEpmcPG0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e6115a-b706-4de5-9b81-1dd67e4b4640"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- The research paper focuses on the development of an artificial intelligence (AI) system for the classification of COVID-19 chest X-ray images.\n",
            "- The major symptoms of COVID-19 include fever, cough, and fatigue, which also appear in pneumonia patients, making it difficult to differentiate between the two during the flu season.\n",
            "- Manual detection of COVID-19 from chest X-ray images is cumbersome and prone to human error, so AI techniques powered by deep learning algorithms are used to enhance the diagnosis process.\n",
            "- The researchers implemented various pre-trained deep learning models such as ResNet, VGG, Inception, and EfficientNet, and developed their own convolutional neural network (CNN) model called DLH-COVID.\n",
            "- The DLH-COVID model achieved the highest accuracy of 96% in detecting COVID-19 from chest X-ray images compared to pneumonia-affected and healthy individuals.\n",
            "- The researchers also developed a web application based on the DLH-COVID model, allowing users to upload chest X-ray images and detect the presence of COVID-19 within seconds.\n",
            "- The AI system and web application have the potential to become a rapid COVID-19 diagnosis method in the future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the custom function to add the prompt templates\n",
        "def summarize_map_reduce_prompt_pdf(pdf_file_path, chunk_size, chunk_overlap, map_prompt, combine_prompt):\n",
        "    # Instantiate LLM model\n",
        "    llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
        "\n",
        "    # Load PDF file\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs_raw = loader.load()\n",
        "\n",
        "    # Create multiple documents\n",
        "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
        "\n",
        "    # Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
        "\n",
        "    # Summarize the chunks\n",
        "    # Using map_reduce chain type with map_prompt and combine_prompt\n",
        "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=map_prompt, combine_prompt=combine_prompt)\n",
        "\n",
        "    # Return the summary\n",
        "    summary = chain.invoke(docs_chunks, return_only_outputs=True)\n",
        "    return summary['output_text']\n"
      ],
      "metadata": {
        "id": "75e6j-Cg_BSl"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summarize_map_reduce_prompt_pdf(pdf_url, 2000, 100, map_prompt, combine_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGThS_dTAo3j",
        "outputId": "d1fec1df-65eb-4b56-b46a-ac6cd1302465"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The research paper focuses on the development and evaluation of an artificial intelligence model, DLH_COVID, for the detection of COVID-19 from chest X-ray images. The researchers collected a dataset of chest X-ray images from COVID-19 patients, pneumonia-affected individuals, and healthy individuals. They implemented various pre-trained deep learning models and developed their own convolutional neural network model, DLH_COVID. The DLH_COVID model achieved the highest accuracy of 96% in detecting COVID-19 from chest X-ray images and outperformed the pre-trained models. A web application based on the DLH_COVID model was also developed, allowing users to upload chest X-ray images and quickly detect the presence of COVID-19. The paper concludes that the DLH_COVID model and web application provide an efficient and user-friendly method for COVID-19 detection from chest X-ray images, with the potential to become a rapid diagnosis method in the future. The paper also discusses the use of transfer learning and pre-trained models in previous COVID-19 X-ray image classification research, as well as the evaluation metrics used and the integration of the DLH_COVID model into a web-based application. The researchers used Google Colab and Microsoft Azure's cloud service for training and deploying the DLH_COVID model. Overall, the research paper provides valuable insights and findings for artificial intelligence researchers working on medical image analysis and COVID-19 detection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XUnEVtU849_"
      },
      "source": [
        "## <font color=blue> TASK 4: Build and test a GenAI app for PDF summarization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import dotenv\n",
        "from langchain_openai import OpenAI\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import streamlit as st"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BA6cRLcK8_V",
        "outputId": "1d9ae4c5-fba7-4926-8cb2-bb146d2e1724"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#summarize_pdf function\n",
        "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap, prompt):\n",
        "    #Instantiate LLM model gpt-3.5-turbo-16k\n",
        "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
        "\n",
        "    #Load PDF file\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs_raw = loader.load()\n",
        "\n",
        "    #Create multiple documents\n",
        "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
        "\n",
        "    #Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
        "\n",
        "    #Summarize the chunks\n",
        "    chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt = prompt)\n",
        "    #Return the summary\n",
        "    summary = chain.invoke(docs_chunks, return_only_outputs=True)\n",
        "    return summary['output_text']"
      ],
      "metadata": {
        "id": "ysoMwUpmLmJt"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "urhXeIwaS6RN"
      },
      "outputs": [],
      "source": [
        "#streamlit app main() function\n",
        "def main():\n",
        "    # Set page config and title\n",
        "    st.set_page_config(page_title=\"PDF Summarizer\", page_icon=\":book:\", layout=\"wide\")\n",
        "    st.title(\"PDF Summarizer\")\n",
        "\n",
        "    # Input pdf file path\n",
        "    pdf_file_path = st.text_input(\"Enter the path to the PDF file:\")\n",
        "    if pdf_file_path != \"\":\n",
        "        st.write(\"PDF file was loaded successfully\")\n",
        "\n",
        "    # Prompt input\n",
        "    user_prompt = st.text_input(\"Enter your prompt:\")\n",
        "    user_prompt = user_prompt + \"\"\"{text}\"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=user_prompt,\n",
        "    )\n",
        "\n",
        "    # Summarize button\n",
        "    if st.button(\"Summarize\"):\n",
        "        summary = summarize_pdf(pdf_file_path, 1000, 20, prompt)\n",
        "        st.write(summary)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzwg6laiL-pZ",
        "outputId": "5849403c-4541-44d9-d2e6-1227169ff42e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-09 12:32:17.941 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.943 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.943 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.945 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.946 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.947 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.948 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.948 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.949 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.955 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.956 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.957 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.958 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.958 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10C8V-CIL4Ti"
      },
      "source": [
        "## <font color=blue> Launch Streamlit app from Google Colab\n",
        "\n",
        "The following lines of code would enable users to launch Streamlit app from Google Colab using [ngrok service](https://ngrok.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaPE0T2iDzwu"
      },
      "outputs": [],
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Brgmtoc7CVKx"
      },
      "outputs": [],
      "source": [
        "!unzip ngrok-stable-linux-amd64.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hle-PIMoQfLs"
      },
      "outputs": [],
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7C6dydMS06y"
      },
      "outputs": [],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1Rduaz0TG-Y"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJtA0iPfgBn_"
      },
      "source": [
        "## <font color=blue> FINAL TASK: Cumulative Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Click the link to explore useful Streamlit library functions:\n",
        "https://docs.streamlit.io/library/cheatsheet"
      ],
      "metadata": {
        "id": "KFTCcg_COEie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import dotenv\n",
        "from langchain_openai import OpenAI\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import streamlit as st"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZJ9w7hoMrRa",
        "outputId": "d17eb221-0560-4883-97af-4846787da1b3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the .env file and invoke the secret API key from the file\n",
        "dotenv.load_dotenv('API.env')\n",
        "OpenAI.api_key = os.getenv(\"OPENAI_KEY\")"
      ],
      "metadata": {
        "id": "48GOe86FMtNm"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "PiEdC80-gP-k"
      },
      "outputs": [],
      "source": [
        "#summarize_pdf function\n",
        "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap, chain_type, prompt):\n",
        "    #Instantiate LLM model gpt-3.5-turbo-16k\n",
        "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
        "\n",
        "    #Load PDF file\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs_raw = loader.load()\n",
        "\n",
        "    #Create multiple documents\n",
        "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
        "\n",
        "    #Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
        "\n",
        "    # Create multiple prompts\n",
        "    prompt = prompt + \"\"\"{text}\"\"\"\n",
        "    combine_prompt = PromptTemplate(input_variables=[\"text\"], template=prompt)\n",
        "    map_prompt = PromptTemplate(template=\"Summarize in bullet points:\\n\\n{text}\", input_variables=[\"text\"])\n",
        "\n",
        "    # Summarize the chunks\n",
        "    if chain_type == \"map_reduce\":\n",
        "        chain = load_summarize_chain(llm, chain_type=chain_type,\n",
        "                                    map_prompt=map_prompt, combine_prompt=combine_prompt)\n",
        "    else:\n",
        "        chain = load_summarize_chain(llm, chain_type=chain_type, prompt=map_prompt)\n",
        "\n",
        "    # Return the summary\n",
        "    return chain.run(docs_chunks)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#streamlit app main() function\n",
        "def main():\n",
        "    # Set page config and title\n",
        "    st.set_page_config(page_title=\"PDF Summarizer\", page_icon=\":book:\", layout=\"wide\")\n",
        "    st.title(\"Sam's GenAI App\")\n",
        "\n",
        "    # Add custom sliders and selectbox for more user interaction\n",
        "    chain_type = st.sidebar.selectbox(\"Chain Type\", [\"stuff\", \"map_reduce\"])\n",
        "    chunk_size = st.sidebar.slider(\"Chunk Size\", min_value=100, max_value=10000, step=100, value=1000)\n",
        "    chunk_overlap = st.sidebar.slider(\"Chunk Overlap\", min_value=10, max_value=1000, step=100, value=20)\n",
        "\n",
        "    # Display warning message\n",
        "    if 'map_reduce' in chain_type:\n",
        "        st.sidebar.warning(\"Map_reduce chain type takes more than 5 mins to generate summary due to prompt latency!\")\n",
        "\n",
        "    # Input pdf file path\n",
        "    pdf_file_path = st.text_input(\"Enter PDF file path:\")\n",
        "\n",
        "    # Prompt input\n",
        "    user_prompt = st.text_input(\"Enter prompt:\")\n",
        "\n",
        "\n",
        "    #Summarize button\n",
        "    if st.button(\"Summarize\"):\n",
        "        #Summarize pdf\n",
        "        summary = summarize_pdf(pdf_file_path, chunk_size, chunk_overlap, chain_type, user_prompt)\n",
        "        st.write(summary)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST8viQioNVWP",
        "outputId": "520b41ec-78af-4dc6-d246-dc5312317dca"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-09 12:32:17.981 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.982 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.982 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.983 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.985 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.985 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.986 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.989 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.989 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.990 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.991 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.991 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.992 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.993 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.994 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.994 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.995 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.998 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:17.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.000 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.001 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.001 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.002 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.004 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.005 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.006 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.007 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.008 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.008 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.009 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.009 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.010 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-09 12:32:18.011 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "xn7-oPQOPNUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4f5e02-b975-48b1-da71-e7a7c1a558e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.133.247.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "141g6WFTPVbM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5312e9-5c89-4dcd-b139-8db27dbdbe76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.133.247.52:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0Kyour url is: https://empty-emus-cough.loca.lt\n",
            "y\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NsY8MxTkSWXQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}